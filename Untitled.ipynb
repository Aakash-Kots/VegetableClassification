{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d57cf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "281588fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-macos in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (2.16.2)\n",
      "Requirement already satisfied: tensorflow==2.16.2 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow-macos) (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.23.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow==2.16.2->tensorflow-macos) (0.38.4)\n",
      "Requirement already satisfied: rich in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (2023.11.17)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/aakashkothari/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-macos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eb56e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    validation_split=0.2  # Adjust according to your needs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe4ad64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 15 classes.\n",
      "Found 3000 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = \"/Users/aakashkothari/Desktop/Kaggle/Vegetables/Vegetable Images/train\"\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(255, 255),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Create validation data generator\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(255, 255),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0e81bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f344ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {v: k for k, v in train_generator.class_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c4c442b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Bean',\n",
       " 1: 'Bitter_Gourd',\n",
       " 2: 'Bottle_Gourd',\n",
       " 3: 'Brinjal',\n",
       " 4: 'Broccoli',\n",
       " 5: 'Cabbage',\n",
       " 6: 'Capsicum',\n",
       " 7: 'Carrot',\n",
       " 8: 'Cauliflower',\n",
       " 9: 'Cucumber',\n",
       " 10: 'Papaya',\n",
       " 11: 'Potato',\n",
       " 12: 'Pumpkin',\n",
       " 13: 'Radish',\n",
       " 14: 'Tomato'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d327a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.layers as layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9509e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "    layers.Flatten(input_shape=(255,255,3)),\n",
    "\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "                    layers.Dense(32, activation=\"relu\"),\n",
    "\n",
    "    layers.Dense(15, activation=\"linear\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a22476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5243d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# # Fit the model with early stopping and validation split\n",
    "# history = model.fit(train_generator,\n",
    "#                     epochs=100, \n",
    "#                     batch_size=32, \n",
    "#                     validation_data=validation_generator, \n",
    "#                     callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8547b487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import mixed_precision\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# model = models.Sequential([\n",
    "#     layers.Conv2D(32, (3, 3), activation='relu', input_shape=(255, 255, 3)),\n",
    "#     layers.MaxPooling2D((2, 2)),\n",
    "#     layers.BatchNormalization(),\n",
    "\n",
    "#     layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#     layers.MaxPooling2D((2, 2)),\n",
    "#     layers.BatchNormalization(),\n",
    "\n",
    "#     layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "#     layers.MaxPooling2D((2, 2)),\n",
    "#     layers.BatchNormalization(),\n",
    "\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "#     layers.Dropout(0.5),\n",
    "#     layers.BatchNormalization(),\n",
    "\n",
    "#     layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "#     layers.Dropout(0.5),\n",
    "#     layers.BatchNormalization(),\n",
    "\n",
    "#     layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "#     layers.Dropout(0.5),\n",
    "#     layers.BatchNormalization(),\n",
    "\n",
    "#     layers.Dense(15, activation='softmax')\n",
    "# ])\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Fit the model and time it\n",
    "start_time = time.time()\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=1,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "print(f\"Total training time: {training_time:.2f} seconds\")\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efb8095",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/Users/aakashkothari/Desktop/model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e92300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65607301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5e9808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6676379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = datagen.flow_from_directory(\n",
    "    \"/Users/aakashkothari/Desktop/Kaggle/Vegetables/Vegetable Images/test\",\n",
    "    target_size=(255, 255),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10cc832",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_generator)\n",
    "predicted_indices = np.argmax(predictions, axis=1)\n",
    "predicted_labels = [class_map[idx] for idx in predicted_indices]\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9981a944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertPredToLabels(pred):\n",
    "    predicted_indices = np.argmax(pred, axis=1)\n",
    "    print(predicted_indices)\n",
    "    return [class_map[idx] for idx in predicted_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2521c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open(\"/Users/aakashkothari/Desktop/Kaggle/Vegetables/Vegetable Images/test/Capsicum/1001.jpg\").convert('RGB')\n",
    "image = image.resize(size=(255,255))\n",
    "img = np.asarray(image)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6315d46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f618e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "# Check the shape after adding batch dimension\n",
    "print(\"Shape after adding batch dimension:\", img.shape)\n",
    "\n",
    "# Make predictions\n",
    "p = model.predict(img / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ab11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "convertPredToLabels(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "218e58be",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/Users/aakashkothari/Desktop/model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/aakashkothari/Desktop/model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/saving_api.py:189\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    183\u001b[0m         filepath,\n\u001b[1;32m    184\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    186\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    187\u001b[0m     )\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[1;32m    190\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[1;32m    191\u001b[0m     )\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    197\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/legacy/saving/legacy_h5_format.py:116\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m opened_new_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opened_new_file:\n\u001b[0;32m--> 116\u001b[0m     f \u001b[38;5;241m=\u001b[39m h5py\u001b[38;5;241m.\u001b[39mFile(filepath, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     f \u001b[38;5;241m=\u001b[39m filepath\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, flags, fapl\u001b[38;5;241m=\u001b[39mfapl)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/Users/aakashkothari/Desktop/model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"/Users/aakashkothari/Desktop/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3738cce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    validation_split=0.2  # Adjust according to your needs\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    \"/Users/aakashkothari/Desktop/Kaggle/Vegetables/Vegetable Images/test\",\n",
    "    target_size=(255, 255),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c864ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aakashkothari/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 229ms/step - accuracy: 0.9923 - loss: 0.3571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35058218240737915, 0.9936666488647461]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0167d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall tensorflow --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5337f9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a336e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow-macos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e33d0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikit-learn version 1.3.0 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n",
      "XGBoost version 2.1.0 has not been tested with coremltools. You may run into unexpected errors. XGBoost 1.4.2 is the most recent version that has been tested.\n",
      "TensorFlow version 2.16.2 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "/Users/aakashkothari/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 229ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.8289795e-07, 8.8840310e-11, 1.7796894e-07, ..., 4.8417060e-06,\n",
       "        7.2758729e-07, 3.6311479e-07],\n",
       "       [1.7300637e-07, 1.9006598e-07, 2.1369924e-08, ..., 1.3135111e-05,\n",
       "        5.0187559e-08, 5.9537115e-06],\n",
       "       [1.1883434e-06, 9.9999595e-01, 1.0238002e-07, ..., 5.6698337e-07,\n",
       "        5.4879568e-08, 1.7833242e-08],\n",
       "       ...,\n",
       "       [2.8073933e-07, 1.8336715e-06, 5.2730645e-08, ..., 3.8634712e-06,\n",
       "        5.7771960e-08, 6.0237841e-07],\n",
       "       [2.0148505e-06, 4.4868700e-10, 3.0506902e-07, ..., 3.2757093e-06,\n",
       "        3.7176255e-06, 2.4420868e-07],\n",
       "       [3.4370410e-06, 9.9997008e-01, 1.6271780e-06, ..., 1.1673313e-05,\n",
       "        1.4127410e-06, 4.7095745e-07]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import coremltools as ct\n",
    "# Load your existing Keras model\n",
    "model_path = \"/Users/aakashkothari/Desktop/Kaggle/Vegetables/model.h5\"\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "model.predict(train_generator)\n",
    "\n",
    "# Save the model in SavedModel format\n",
    "\n",
    "# model.export(\"/Users/aakashkothari/Desktop/model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de231522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 235ms/step - accuracy: 0.9991 - loss: 0.3309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3286665081977844, 0.9991666674613953]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ee167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_config = ct.ClassifierConfig([\"class_map\"])\n",
    "image_input = ct.ImageType(scale=1/255)\n",
    "mlmodel = ct.convert(model, source=\"tensorflow\", convert_to=\"mlprogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e671157",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "607959f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open(\"/Users/aakashkothari/Desktop/Kaggle/Vegetables/Vegetable Images/test/Capsicum/1001.jpg\").convert('RGB')\n",
    "image = image.resize(size=(255,255))\n",
    "img = np.asarray(image)\n",
    "img.shape\n",
    "img = np.expand_dims(img, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc3982a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(img/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "285db96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.98755586e-07 1.05222159e-06 5.94174416e-08 2.78259631e-06\n",
      "  1.03002526e-06 6.46586840e-10 9.99988198e-01 8.28587510e-09\n",
      "  1.31667734e-08 5.49912386e-07 9.73232090e-07 4.32464446e-08\n",
      "  3.60496733e-06 1.61064651e-09 1.40869145e-06]]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2fd979a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n",
      "['Capsicum']\n"
     ]
    }
   ],
   "source": [
    "print(convertPredToLabels(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5447ced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
